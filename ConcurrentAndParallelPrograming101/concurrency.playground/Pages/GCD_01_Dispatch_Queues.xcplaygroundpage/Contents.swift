//:[Spis TreÅ›ci](Spis_Tresci) | [Wstecz](@previous) | [NastÄ™pna strona](@next)
/*:
 > # GCD Dispatch Queues
 */

import Foundation
import PlaygroundSupport

PlaygroundPage.current.needsIndefiniteExecution = true


/*:

 # [Grand Central Dispatch - GCD](https://developer.apple.com/documentation/DISPATCH)

 Tworzenie, zarzÄ…danie i synchronizacja wÄ…tkÃ³w nie jest taka prosta. CiÄ™Å¼ko jest dobraÄ‡ odpowiedniÄ… iloÅ›Ä‡ wÄ…tkÃ³w do dostÄ™pnych rdzeni/procesorÃ³w. Trzeba pomyÅ›leÄ‡ teÅ¼ o aktualbym obciÄ…Å¼eniu systemu. Aby nieco odciÄ…zyÄ‡ developera od tego rodzaju zadaÅ„ Apple napisaÅ‚o GCD. Jest to zestaw ficzerÃ³w/umiejÄ™tnoÅ›ci jÄ™zyka, bibliotek dziaÅ‚ajÄ…cych w czasie Å¼ycia aplikacji oraz na poziomie systemu, ktÃ³re wspierajÄ… wykonywanie kodu na wielu procesorach/rdzeniach.

 Warto wiedzieÄ‡, Å¼e wszystko o czym rozmawialiÅ›my w `NSOperation` jest obiektowÄ… nakÅ‚adkÄ… na API dostarczone przez GCD.

 # Dispatch Queue

 **Dispatch Queue** jak nazwa wskazuje jest kolejkÄ…. Dodajemy do niej bloki operacji ktÃ³re sÄ… wykonywane serialnie (jeden za drugim) w kolejnoÅ›ci First In First Out. **Kolejka odpowiada za zarzÄ…dzanie i wykonywanie zadaÅ„, ktÃ³re sÄ… na niÄ…Â dodane**.

 Gdy dodajemy zadanie do wykonania na kolejce to system zarzÄ…dza pulÄ… wÄ…tkÃ³w. Te wÄ…tki sÄ… tworzone wczeÅ›niej i reuÅ¼ywane miÄ™dzy rÃ³Å¼nymi kolejkami. Ogranicza to problem tworzenia i niszczenia wÄ…tkÃ³w, ktÃ³ry z punktu widzenia czasu procesora jest kosztowny. JeÅ¼eli wÄ…tkÃ³w jest za maÅ‚o to system stworzy kolejny. Co jest waÅ¼ne to nie mamy kontroli nad tym na ktÃ³rym wÄ…tku bÄ™dÄ… wykonywane zadania z kolejki.

## Serial queue

 **Serial queue** wywoÅ‚uje tylko jeden blok na raz. Czyli nie wystartuje nastÄ™pnego taks-a aÅ¼ poprzedni nie zostanie ukoÅ„czony.

 Natomiast moÅ¼na mieÄ‡ kilka takich kolejek i wtedy z perspektywy tych blokÃ³w kilka na raz bÄ™dzie jednoczeÅ›nie wykonywanych.

## Concurent queue

 **Concurrent queue** woÅ‚a blok rÃ³wnieÅ¼ w kolejnoÅ›ci FIFO ale nie czeka na jego zakoÅ„czenie zanim wywoÅ‚a kolejny w kolejce. Oznacza to, Å¼e nie moÅ¼na polegaÄ‡ na kolejnoÅ›ci w jakiej zakoÅ„czÄ… siÄ™ zadania.

 ## Main Queue

 Jest to **seryjna** kolejka przeznaczona na rzeczy zwiÄ…zane z aktualizacjÄ… UI wykonujÄ…ca jedno zadanie na raz. Wszystkie zadania sÄ… uruchamiane na gÅ‚Ã³wnym wÄ…tku aplikacji. Jest to wÄ…tek tworzony przy uruchomieniu aplikacji, ktÃ³remu system przydziela najwyÅ¼szy priorytet tak aby aplikacja byÅ‚a rezponsywna.

WaÅ¼ne jest aby nie utoÅ¼samiaÄ‡ `main queue` z `main thread`. MoÅ¼e siÄ™ zdarzyÄ‡, Å¼e inne kolejki teÅ¼ bÄ™dÄ… odpalaÄ‡ zadania na gÅ‚Ã³wnym wÄ…tku. Zdanie wiÄ™cej moÅ¼na przeczytaÄ‡ na [Main thread and main queue: whatâ€™s the difference?](https://www.hackingwithswift.com/quick-start/concurrency/main-thread-and-main-queue-whats-the-difference)

 # Tworzenie Kolejki Seryjnej

 ZaletÄ… takiej kolejki jest to, Å¼e synchronizuje nam dostÄ™p do wspÃ³Å‚dzielonego zasobu. GwarantujÄ…c, Å¼e w danym czasie tylko jeden wÄ…tek z niego korzysta.

 */

let serialQueue1 = DispatchQueue(label: "lekko.techno.serial.queue.1")

/*:

 ### QoS - Quality of Service

MoÅ¼emy daÄ‡ dla systemu wskazÃ³wkÄ™ jak waÅ¼na jest dla nas ta kolejka czyli jak czÄ™sto sytem powinien wykonywaÄ‡ zadania na niÄ… przesÅ‚ane. Po konkretne wartoÅ›ci zapraszam rzuciÄ‡ okiem do dokumentacji lub kodu.

 */

let serialQueue2 = DispatchQueue(label: "lekko.techno.serial.queue.2", qos: .default)


/*:

 # Tworzenie Kolejki "RÃ³wnolegÅ‚ej"

 */

let concurrentQueue = DispatchQueue(label: "lekko.techno.concurrent.queue.1", attributes: .concurrent)

/*:

 # Global Queues

 System dostarcza nam juz globale kolejki rÃ³wnolegÅ‚e z ktÃ³rych moÅ¼emy korzystaÄ‡.

 * [Stara ale jara dokumentacja](https://developer.apple.com/library/content/documentation/General/Conceptual/ConcurrencyProgrammingGuide/OperationQueues/OperationQueues.html#//apple_ref/doc/uid/TP40008091-CH102-SW5)
 * [Nowsza dokumentacja](https://developer.apple.com/documentation/dispatch/dispatchqueue/2300077-global)

 JeÅ¼eli potrzebujemy rÃ³wnolegÅ‚ej kolejki to lepiej jest uÅ¼ywaÄ‡ tych dostarczonych przez system. Pozwoli to ograniczyÄ‡ iloÅ›Ä‡ wÄ…tkÃ³w uzywanych przez aplikacje. Jak pokazywaliÅ›my w poprzednich przykÅ‚adach gdy ich jest za duÅ¼o to caÅ‚y system przestaje byÄ‡ wydajny.

 */

let systemQueue = DispatchQueue.global(qos: .background)

/*:

 ## Dodawanie ZadaÅ„

 Zadania moÅ¼emy dodawaÄ‡ bezpoÅ›rednio do kolejek przekazujÄ…c im closure do wykonania.

 ### Synchroniczne i Asynchroniczne

 Kolejki seryjne (serial) oraz rÃ³wnolegÅ‚e (concurent) mogÄ… wykonywaÄ‡ zadania synchronicznie lub asynchronicznnie.

 JeÅ¼eli zadanie jest wykonywane **synchronicznie** oznacza to, Å¼e wykonanie kodu jest _zablokowane_ na tej linijce. Dopiero gdy zadanie siÄ™ wykona siÄ™ to kod _pobiegnie_ dalej. Jest to takie samo zachowanie jak byÅ›my wywoÅ‚ali funkcjÄ™ (z tÄ… rÃ³Å¼nicÄ…, Å¼e funkcja zostaÅ‚a by uruchomiona na aktualnym wÄ…tku). Do momentu zakoÅ„czenia dziaÅ‚ania funkcji program w aktualnym miejscu nie poruszy siÄ™ do przodu.

 Zadanie wysÅ‚ane na kolejkÄ™ **asynchroniczne** nie czeka na zakoÅ„czenie tego zadania. Bieg programu natychmiast przechodzi do nastepnej linijki kodu.

 */

xtimeBlock("ğŸ”ª Dodawanie ZadaÅ„ 1") {
    
    print(#line ,"ğŸ Before adding ALL tasks")

    print(#line, "ğŸ¦Š Before on serial 1 with sync")
    // "As an optimization, this function invokes the block on the current thread when possible."
    serialQueue1.sync {
        sleep(1)
        print("ğŸ¦Š111111111111 -> GÅ‚Ã³wny wÄ…tek: \(Thread.isMainThread)", #line)
    }
    print(#line, "ğŸ¦Š After on serial 1 with sync")


    print(#line, "ğŸ¥ Before on private concurrent with sync")
    concurrentQueue.sync {
        sleep(1)
        print("ğŸ¥333333333333 -> GÅ‚Ã³wny wÄ…tek: \(Thread.isMainThread)", #line)
    }
    print(#line, "ğŸ¥ After on private concurrent with sync")


    print(#line, "ğŸ„ Before on global system with sync")
    systemQueue.sync {
        sleep(1)
        print("ğŸ„555555555555 -> GÅ‚Ã³wny wÄ…tek: \(Thread.isMainThread)", #line)
    }
    print(#line, "ğŸ„ After on global system with sync")


    print(#line, "â„¹ï¸ Adding async tasks...")


    print(#line, "ğŸ¦‹ Before on serial 2 with async")
    serialQueue2.async {
        sleep(1)
        print("ğŸ¦‹222222222222 -> GÅ‚Ã³wny wÄ…tek: \(Thread.isMainThread)", #line)
    }
    print(#line, "ğŸ¦‹ After on serial 2 with async")


    print(#line, "ğŸª² Before on private concurrent with async")
    concurrentQueue.async {
        sleep(1)
        print("ğŸª²444444444444 -> GÅ‚Ã³wny wÄ…tek: \(Thread.isMainThread)", #line)
    }
    print(#line, "ğŸª² After on private concurrent with async")


    print(#line, "ğŸˆ Before on global system with async")
    systemQueue.async {
        sleep(1)
        print("ğŸˆ666666666666 -> GÅ‚Ã³wny wÄ…tek: \(Thread.isMainThread)", #line)
    }
    print(#line, "ğŸˆ After on global system with async")


    print("ğŸ After adding ALL tasks\n")
}

/*:

 Po wyniku w konsoli widaÄ‡, Å¼e wykonanie kodu zatrzymaÅ‚o siÄ™ gdy zadania byÅ‚y dodawane synchronicznie i nie czekaÅ‚o gdy zadania byÅ‚y dodawane asynchronicznie.

Poprzedni przykÅ‚ad pokazaÅ‚ wszystkie moÅ¼liwe kombinacje jakie mogÄ… wystÄ…piÄ‡ w doddawaniu zadaÅ„ do kolejki (serial sync, serial async, concurent sync, concurent async). W przykÅ‚adzie niÅ¼ej skupimy siÄ™ na _serial sync_:
 */


xtimeBlock("ğŸ“ DuÅ¼o zadaÅ„ seryjnych (sync)") {
 
    for i in 0...10 {
        print("ğŸ›«")
        
        // przed wywoÅ‚aniem kolejnego bloku zaczeka na zakoÅ„czenie poprzedniego
        serialQueue1.sync {
            sleep(1)
            let message = String(repeating: "\(i)", count: 5)
            print(message + " -> GÅ‚Ã³wny wÄ…tek: \(Thread.isMainThread)")
        }
        print("ğŸ›¬")
    }
}

/*:

 MoÅ¼e siÄ™ zdaÅ¼yÄ‡, Å¼e jako optymalizacje system wywoÅ‚a zadanie z kolejki na gÅ‚Ã³wnym wÄ…tku. Istotne natomiast jest to, Å¼e za kaÅ¼dym razem kod _czeka_ na zakoÅ„czenie zadania zanim przejdzie dalej.

 W przykÅ‚adzie niÅ¼ej dodamy wszystkie zadania asynchronicznie:

 */

xtimeBlock("ğŸ‡ DuÅ¼o zadaÅ„ seryjnych (async)") {
    
    for i in 0...10 {
        print("ğŸ›«")
        serialQueue1.async {
            sleep(1)
            let message = String(repeating: "\(i)", count: 5)
            print(message + " -> GÅ‚Ã³wny wÄ…tek: \(Thread.isMainThread)")
        }
        print("ğŸ›¬")
    }

}

/*:

 Dodanie zadaÅ„ i czas wykonania caÅ‚ej pÄ™tli byÅ‚ praktycznie _natychmiastowy_. Dopiero po pewnym czasie widaÄ‡, Å¼e zadania wykonywaÅ‚y siÄ™ w kolejnoÅ›ci w jakiej zostaÅ‚y dodane do kolejki.

## Wiele seryjnych kolejek

 WiemÅ¼y Å¼e gdy zadanie dodajemy asynchronicznie to nie czekamy na zakoÅ„czenie tego zadania. DziÄ™ki temu w zaleÅ¼noÅ›ci od tego co chcemy zrobiÄ‡ moÅ¼na zlecaÄ‡ dodawanie zadaÅ„ do rÃ³Å¼nych kolejek:

 */

xtimeBlock("ğŸ‘¯â€â™€ï¸ Raz jedna seryjna raz druga seryjna (async)") {
    
    for i in 0...10 {
        if i.isMultiple(of: 2) {
            serialQueue1.async {
                sleep(1)
                let message = String(repeating: "\(i)", count: 20)
                print(message + "Serial 1 -> GÅ‚Ã³wny wÄ…tek: \(Thread.isMainThread)")
            }
        } else {
            serialQueue2.async {
                sleep(1)
                let message = String(repeating: "\(i)", count: 20)
                print(message + "Serial 2 -> GÅ‚Ã³wny wÄ…tek: \(Thread.isMainThread)")
            }
        }
    }
}

/*:

 AnalizujÄ…c wynik dziaÅ‚ania tego przykÅ‚adu w konsoli widaÄ‡, Å¼e caÅ‚oÅ›Ä‡ wykonaÅ‚a siÄ™ szybciej. Podzielenie pracy teÅ¼ byÅ‚o trywialne. Sprowadza siÄ™ do uzycia 2 seryjnych kolejek wysyÅ‚ania zadaÅ„ na nie zgodnie z _jakÄ…Å› logikÄ…_.

### Dodawanie zadaÅ„ do kolejki rÃ³wnolegÅ‚ej

Nie ma znaczenia czy kolejka jest serialna czy rÃ³wnolegÅ‚a. Gdy dodajemy zadanie uÅ¼ywajÄ…c metody `sync` to bÄ™dziemy _czekaÄ‡_ a gdy `async` to program _pobiegnie_ dalej. PoniÅ¼sze dwa przykÅ‚ady to ilustrujÄ….

To co jeszcze rzuca siÄ™ w oczy to, Å¼e zadania na kolejce rÃ³wnolegÅ‚ej wykonaÅ‚y siÄ™, no cÃ³Å¼, rÃ³wnolegle.

 */

xtimeBlock("ğŸŒ²ğŸŒ²ğŸŒ² DuÅ¼o zadaÅ„ rÃ³wnolegÅ‚ych (sync)") {
    
    for i in 0...10 {
        print("ğŸ›«", i)
        
        // przed wywoÅ‚aniem kolejnego bloku zaczeka na zakoÅ„czenie poprzedniego
        concurrentQueue.sync {
            sleep(1)
            let message = String(repeating: "\(i)", count: 20)
            print(message + " -> GÅ‚Ã³wny wÄ…tek: \(Thread.isMainThread)")
        }

        print("ğŸ›¬", i)
    }
}

xtimeBlock("ğŸ›£ğŸ›£ğŸ›£ DuÅ¼o zadaÅ„ rÃ³wnolegÅ‚ych (async)") {
    
    for i in 0...10 {
        print("ğŸ›«", i)

        concurrentQueue.async {
            sleep(1)
            let message = String(repeating: "\(i)", count: 20)
            print(message + " -> GÅ‚Ã³wny wÄ…tek: \(Thread.isMainThread)")
        }

        print("ğŸ›¬", i)
    }
}

/*:

## DispatchWorkItem i  `Main Queue`

Zadanie ktÃ³re chcemy wykonaÄ‡ moÅ¼emy opakowaÄ‡ w obiekt klasy `DispatchWorkItem`. Chyba najczÄ™strzym powodem aby to robiÄ‡ w ten sposÃ³b jest opcja anulowania zadania. W przypadku API z closure-s zadanie jest wysÅ‚ane i nie mamy jak tego zrobic. MajÄ…c referencje do `work item`a moÅ¼emy zawoÅ‚aÄ‡ na nim metodÄ™ [`cancel`](https://developer.apple.com/documentation/dispatch/dispatchworkitem/1780910-cancel)

 */


let taskToDo  = DispatchWorkItem {
    print("Jest Robota  -> GÅ‚Ã³wny wÄ…tek: \(Thread.isMainThread)");
}

/*:

 DoÅ›Ä‡ czÄ™sto zdarza siÄ™ potrzeba _wrÃ³cenia_ na gÅ‚owny wÄ…tek. NajczÄ™Å›ciej wykonuje siÄ™ _strzaÅ‚_ sieciowy i rezultat odÅ›wieÅ¼a UI. Te zmiany muszÄ… byÄ‡ wykonane na gÅ‚Ã³wnym wÄ…tku.

 Aby _wrÃ³ciÄ‡_ na gÅ‚Ã³wny wÄ…tek moÅ¼emy zleciÄ‡ wykonanie zadania na `main queue`.

 */


xtimeBlock("â›ºï¸ WoÅ‚amy GÅ‚Ã³wny WÄ…tek") {
    
    Thread {
        print("Z innego wÄ…tku...  -> GÅ‚Ã³wny wÄ…tek: \(Thread.isMainThread)");
        DispatchQueue.main.async(execute: taskToDo)
    }
    .start()
}

/*:

 # Za duÅ¼o wÄ…tkÃ³w

 Im wiÄ™cej jest tworzonych prywatnych kolejek tym wiÄ™cej wÄ…tkÃ³w jest tworzonych. Komupter ma ograniczone zasoby. Jak juÅ¼ wczeÅ›niej o tym byÅ‚o wspominane to moÅ¼e spowodowaÄ‡ pogorszenie wydajnoÅ›ci.

 Jednym ze sposobÃ³w na radzenie sobie z tym jest uÅ¼ywanie globalnych kolejek. Natomiast sÄ… one rÃ³wnolegÅ‚e. Kolejka seryjna ma tÄ… zaletÄ™, Å¼e wiemy Å¼e zadania bÄ™dÄ… siÄ™ na niej wykonywaÄ‡ _jedno za drugim_.

 ## Oddelegowanie pracy kolejki

 Okazuje siÄ™, Å¼e moÅ¼na utworzyÄ‡ kolejkÄ™ seryjnÄ… ale zleciÄ‡ jej uÅ¼ycie kolejki globalnej. W ten sposÃ³b dostajemy dziaÅ‚anie kolejki seryjnej a reuÅ¼ywamy wÄ…tki przeznaczone na kolejki globalne.

 */


timeBlock("ğŸš„ Threads") {

    let targetQueue = DispatchQueue(label: "lekko.techno.threads.target", attributes: .concurrent)

    let sq1 = DispatchQueue(label: "lekko.techno.threads.1", target: targetQueue)
    let sq2 = DispatchQueue(label: "lekko.techno.threads.2", target: targetQueue)

    func jobToDo(queue: String, index: Int) {
        print("ğŸ›« starting job", index, "on", queue)
        sleep(1)
        print("ğŸ›¬ done job", index, "on", queue)
    }

    for index in 0...3 {
        sq1.async { jobToDo(queue: sq1.label, index: index) }
        sq2.async { jobToDo(queue: sq2.label, index: index) }
    }
}



//: [Wstecz](@previous) | [NastÄ™pna strona](@next)
